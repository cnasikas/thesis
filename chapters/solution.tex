%!TEX root = ../thesis.tex
\chapter{Solution}
\label{solution}

In our solution a public blockchain is used as the controller of the application. It is responsible for keeping an
audit, immutable, tamper-proof and transparent log of all actions of the participants.

Blockchain does not provides an extra security layer concerning datasets. The datasets are stored off-chain, data controllers are responsible for the security of their system and the participants can still collaborate outside the Blockchain network. Nevertheless, the use of the Blockchain can guarantee accountability, auditability and provenance tracking of the data increasing the trust for the system.

\section{Participants}
\label{solution:entities}

There are three main roles consisting the application: the data controller, the data processor
and the data requester. The first two are also defined in the context of GDPR (ยง~\ref{problem:regulations}).
GDPR defines another role, that of data subject; the owner of the data.
In our scheme we assume that the data controller already has consent to access or forward the data or she is at the same time the data subject and the data controller.

\subsection{Data Controller}
\label{solution:entities:data_controller}

The data controller is in charge of a data set. It run on behalf of a data subject (person)
that authorizes the data controller to access its personal data, with the possibility of forwarding
them to a data processor that will be responsible for processing the data on behalf of controller~\cite{DBLP:journals/corr/NeisseSF17}. Data

\subsection{Data Processor}
\label{solution:entities:data_processor}

The data processor is responsible for processing data on behalf of the data controller. It listens for data processing requests and returns, along with the output of the process, a Zero Knowledge Proof of correct computation over the requested data set.

\subsection{Data Requester}
\label{solution:entities:data_req}

The requester can be any entity that requests a computation over a data set. It can be a research center, a university, a machine learning algorithm or any individual. The requester expects, along with the output, a proof of correct computation over the requested data set that verifies at the end of the processing.

\section{Trust model}
\label{solution:trust_model}

Before we explain in detail our architecture, we would like to introduce our thread model and what exactly our goals are. It is important to understand the possible roles of adversaries, their strengths and their resources.

In our model we assume that the involved entities that interact with a data set---the data controller and the data processor---are identified and verified through a public key infrastructure (PKI)~\cite{adams_understanding_2003}. Furthermore, each entity is a trusted entity with certain trust properties. In particular, the data controller is trusted for integrity and confidentiality and the data processor only for confidentiality.

Adversaries can be categories in 4 categories:

\begin{itemize}
  \item Malicious data controller
  \item Malicious data processor
  \item Malicious data requestor
  \item Malicious public user
\end{itemize}

\section{Algorithms}
\label{solution:algorithms}

The system should support only a set of open-source algorithms that have been analyzed and constructed to be privacy-preserving with the use of techniques such as k-anonymity~\cite{Samarati98protectingprivacy} and l-diversity~\cite{Aggarwal2008}. This algorithms should return only de-identified aggregated results.

The supported algorithms are:

\begin{enumerate}
  \item Sum
  \item Average
  \item Count
  \item Maximum
  \item Median
  \item Minimum
\end{enumerate}

The above algorithms are not considered to be privacy-preserving as it is outside the scope of the initial prototype and should be implemented on future work(ยง~\ref{future_work:ppq}).

\section{Zero-Knowledge Verifiable Computation}
\label{solution:proof}

Every data processor provides a proof of correctness for the execution of a computation on a given dataset without revealing the dataset itself. As the processor is obligated to provide a proof---a rational verifier rejects a computation without it---it is impossible for the processor a) to pretend that it done a processing without actually make any computation at all; b) to process a different dataset of its choice; c) to execute a different algorithm other than the requested one. It is evident that a Zero-Knowledge proof of computation plays a crucial role as it address various threats by malicious processors and enforce them to be honest.

Constructions of zkSNARKs require a one-time trusted setup in which a common-reference string (CRS) is generated; the public parameters of the system. The CRS is used to construct and verify proofs. Proof generation and verification requires two publicly available keys which derived from the CRS: the evaluation key $ek_f$ and the verification key $vk_f$. For each of the available algorithms processors use, a trusted setup must be done to produce the key pair $(ek_f, vk_f)$. Anybody that can obtained the trapdoor information corresponding to the CRS can produce fake proofs. For that reason, whomever runs the setup should be trusted. Various alternatives to bypass the trusted party---such as secure multi-party computation for CRS generation~\cite{zcash_mpc} or multi-string models~\cite{groth2014cryptography} where a set of untrusted authorities generate a random trusted string---have been proposed. In our solution, we assume that the trusted entity, that registers and verifies the parties through the PKI, is also responsible for key generation and distribution. The distribution can be done either by saving the public parameters on the blockchain or in a publicly available server.

The processor executes an algorithm $F$ with public input $u$ and private input $w$. Using  the evaluation key $ek_f$ it generates a zero knowledge proof with which the requestor using the verification key $vk_f$ can verify that the processor executed the algorithm $F$ correctly with inputs $u$ and $w$.

First, the data processor want to prove to the verifier that the computation is indeed done on the requested dataset without disclosing the dataset to it. The dataset is the private input $w$. For better understanding of the construction of the proof we define a game where tree participants are involved: a trusted oracle, a  computationally bounded processor and a requestor. The trusted oracle has a list of datasets and their hashes. The oracle cannot cheat or collaborate with any of the participant and for the same dataset it produces the same hash. At any moment the oracle selects randomly a dataset, gives it to the processor and announce the hash of the dataset to the requestor. The requestor ask the processor to compute the hash of the dataset as a proof. The requestor accepts the proof if and only if the hash of the processor match the hash of the oracle and rejects otherwise. The processor is forced to correctly compute the hash of the dataset as it is the only way to convince the requestor; hash functions are one-way and the oracle is trusted. Let's modify our game and assume now that the oracle gives the hash of the dataset to both the processor and requestor. The processor can easily convince the requestor without computing the hash; it knows the hash beforehand. To countermeasure that, the requestor demands from the processor to produce a proof of verifiable computation. It gives as function $F$ the same hash function $H$ the oracle used and ask the processor to generate a proof for $F = H(h, d)$ where $d$ is the dataset given by the oracle and $h$ the hash of it. The hash is the public input $u$. As processor wants to disclose the dataset $d$ it produces a zero knowledge proof. The requestor verifies the proof and accept if and only if the proof is valid. Again, the processor can not done anything but to comply and computes the digest. The data controller combined with the blockchain acts as the trusted oracle. The data controller is trusted to publish in the correct digest of the dataset in the blockchain and the immutability property of it prevent a malicious processor to change the digest to its preferences.

What remains, is to include inside $F$ the processing procedure of the dataset. The algorithm $F$ with private inputs $d$ and public input $h$, for which a zero knowledge proof of correct computation is generated, consists of a) hash generation of dataset $d$; b) dataset processing.

Informally, let $d$ be a private dataset, $H$ a cryptographic hash function and $h = H(d)$ the digest of $d$ over $H$. Let $\calp$ be a prover (data processor) and $\calv$ the verifier (data requestor). Prover $\calp$ produces a zkSNARK proof (ยง~\ref{zkp:snarks}) $\pi$ for the following \textbf{NP statement}:

Given the public digest $h$, an outsourced function $F$ and an output $y$ I know a private dataset $d$ such that:
  \begin{enumerate}
    \item $H(d) = h$
    \item $F(d) = y$
  \end{enumerate}

The irreversibility of cryptographic hash function in conjunction with the immutability of Blockchain and the trust for data integrity to data controller, that produced the digest of the dataset in the first place, guarantees that indeed the prover $\calp$ processed the requested dataset without revealing it.

\begin{algorithm}[!htb]
  \caption{Zero Knowledge Proof}\label{alg:zkp}
  \begin{algorithmic}[1]
  \Function{\sf compute}{$F, $$d$, $h$, $ek_f$, $s$}
    \Let{\textsf{valid}}{\textsf{false}}
    \Let{h^{'}}{H(d)} \Comment{Get the digest of the dataset}
    \If{$h^{'} == h$} \Comment{Check if the digest match}
      \Let{\textsf{valid}}{\textsf{true}}
    \EndIf
    \Let{y}{\textsf{$F$($d$)}} \Comment{Process dataset}
    \Let{\textsf{out}}{\textsf{($y$, valid, $s$)}}
    \State \Return{($\pi$, out)} \Comment{Return results}
  \EndFunction
  \Procedure{zkp}{$ek_f$, $F$, $u$, $w$}
    \Let{d}{w} \Comment{Private input}
    \Let{(h, s)}{u} \Comment{Public input}
    \Let{(\pi, out)}{\textsf{compute($F$, $d$, $h$, $ek_f$, $s$)}}
  \EndProcedure
  \end{algorithmic}
\end{algorithm}

\section{Flow}
\label{solution:flow}

\subsection{Dataset Registration}
\label{solution:flow:reg_data}

Naturally, for datasets to be available for processing a data registration process is needed. Anyone who register a dataset automatically becomes a data controller who is responsible for the availability and quality of it. The dataset should be publicly available on any location of choice provided that the controller expose an API for data retrieval. The location can be in a distributed file system~\cite{ipfs}, a decentralized cloud storage~\cite{storj} or a central server. As long as the involved participants communicate over the same protocol the choice is irrelevant; the system can be agnostic concerning data storage.

The confidentiality of the dataset must rely solely on cryptographic primitives with strong guarantees. Therefore, every dataset, before stored, is encrypted using the symmetric encryption algorithm \verb|AES| with \verb|256-bit| key length and \verb|CTR| as mode of operation. For each dataset a different encryption key is created and used. This approach bear the burden of key generation and management but on the other hand if an attacker manages to obtain a key the security of other datasets is not compromised~\cite{schneier1997improved}.The hash of contents of the unencrypted dataset is computed, and stored in the blockchain, using the cryptographic hash function \verb|SHA256|. As discussed in~\ref{solution:proof}, the hash of the file plays an important role in the application.

A dataset is actually registered and available when a \textbf{register} transaction is sent to blockchain, signed by the data controller. The transaction needs to include the name of the dataset, a category, the location (URI) and the checksum (hash) of the file. From the name of the dataset a unique persistent identifier is created, to which all participants refer to. Two datasets with the same name cannot be saved; the transaction is rejected in the case of name duplication.

The data registration procedure is summarized in Algorithm~\ref{alg:data_registration}.

\begin{algorithm}[!htb]
  \caption{Dataset registration}\label{alg:data_registration}
  \begin{algorithmic}[1]
  \Function{\sf save}{file}
      \Let{h}{H(file)}
      \Let{k}{\calg}
      \Let{c}{Enc_{k}(file)}
      \Let{uri}{store(c)}
      \State \Return{$(h, k, uri)$}
  \EndFunction
  \Function{\sf broadcast}{name, uri, category, hash}

        \Let{h_{meta}}{H(name || uri || category || hash)}
        \Let{tx}{(name, uri, category, hash, h_{meta})}
        \State $tx$.send()
        \State \Return{$tx$}
  \EndFunction
  \Procedure{\sf register}{name, file, category}
    \Let{(h, k, uri)}{save(file)}
    \Let{tx}{broadcast(name, uri, category, h)}
    \State \Return{$(tx, k)$}
  \EndProcedure
  \end{algorithmic}
\end{algorithm}

\begin{figure}[ht!]
  \begin{tikzpicture}
    \node[blockchain] (blockchain) at (0,0){Blockchain};

    \begin{scope}[node distance=4cm]
      \node[node, anchor=west] (owner) at (0,-5) {Data Controller};
      \node[database] (db) [below right=of owner] {Datastore};
      \draw[<->] (owner) -- (db) node[midway,left] {$Enc_k(data)$};
      \draw[<-] ([xshift=-1em]owner.north) -- ([xshift=-1em]2,-0.5);
      \draw[->] ([xshift=1em]owner.north) -- ([xshift=1em]2,-0.5) node[midway,right] {$Tx(\{name, location, category, digest, address, hashMeta\}, "register\_data")$};
    \end{scope}

  \end{tikzpicture}
  \caption{Data registration}
  \label{fig:arc:reg}
\end{figure}

\subsection{Entity Registration}
\label{solution:flow:entity_reg}

\begin{enumerate}
  \item Data controller generates an asymmetric encryption key pair
  \item A trusted entity registers data controller's availability by initiating a transaction that saves processors name and public key on the blockchain
\end{enumerate}

\begin{algorithm}[!htb]
  \caption{Entity registration}\label{alg:entity_registration}
  \begin{algorithmic}[1]
  \Procedure{\sf register\_entity}{name, $p_k$, address}
    \Let{tx}{(name, p_k, address)}
    \State $tx$.send()
    \State \Return{$tx$}
  \EndProcedure
  \end{algorithmic}
\end{algorithm}

\begin{figure}[ht!]
  \begin{tikzpicture}
    \node[blockchain] (blockchain) at (0,0){Blockchain};

    \begin{scope}
      \node[node, anchor=west] (controller) at (0,5) {PKI};
      \draw[<-] ([xshift=-1em]controller.south) -- ([xshift=-1em]2,0.5);
      \draw[->] ([xshift=1em]controller.south) -- ([xshift=1em]2,0.5) node[midway,right] {$Tx(\{name, pubKey, address\}, "register\_entity")$};
    \end{scope}

  \end{tikzpicture}
  \caption{Entity Registration}
  \label{fig:arch:entity_reg}
\end{figure}

\subsection{Request for processing}
\label{solution:flow:pr_req}

A request for processing is the procedure where a participant of the network request a specific processing algorithm to be performed on a dataset of its choice. The requestor can only choose from datasets that are registered on the network and publicly available on the blockchain. A request for data processing is registered when the requestor sign and sent a request transaction to the blockchain. In its payload the public key of the requestor is included. The public key is needed by the processor to be able to encrypt data processing results as it crucial to be private from other parties. When a request is registered, a \verb|request| event is emitted notifying the interested parties. All data controllers are listening to \verb|request| events and are responsible for notifying a data processor for that request. The data controller, if the request concerns its dataset, selects randomly a data processor and encrypts the symmetric key of the dataset with its public key. The choice of the data processor could be also done sequentially; the data controller choose the next in line data processor. Selection by popularity in the existence of a decentralized ranking system is a another viable option. A transaction is sent to the blockchain to notify the selected data processor passing the id of the request and the encrypted symmetric key.

The request for processing procedure is summarized in Algorithm~\ref{alg:data_request}.

\begin{algorithm}[!htb]
  \caption{Request for processing}\label{alg:data_request}
  \begin{algorithmic}[1]
  \Function{\sf notify}{$e$}
    \State $p \rselect \{ p_1, p_2, \dots p_n \}$ \Comment{Select randomly processor}
    \Let{(requestID)}{e}
    \Let{tx}{(p)}
    \Let{(pk_p)}{tx.send()} \Comment{Get processor public key}
    \Let{c}{Enc_{pk_p}(k)} \Comment{Encrypt symmetric key}
    \Let{tx}{(requestID, c)} \Comment{Notify processor}
    \State $tx$.send()
    \State \Return{$tx$}
  \EndFunction
  \Procedure{\sf watch}{\null}
    \While{$e \in$ events['request']} \Comment{Listen data processing requests}
      \CommentLine{Check if the controller is the owner of the dataset}
      \If{isOwner($e$.datasetOwner)}
        \State notify($e$) \Comment{Notify processor}
      \EndIf
    \EndWhile
  \EndProcedure
  \Procedure{\sf request}{datasetID, algorithmID, $p_{k}$}
    \Let{tx}{(datasetID, algorithmID, p_{k})} \Comment{Request for processing}
    \State $tx$.send()
    \State \Return{$tx$}
  \EndProcedure
  \end{algorithmic}
\end{algorithm}

\begin{figure}[ht!]
  \begin{tikzpicture}

    \node[blockchain] (blockchain) at (0,0){Blockchain};

    \begin{scope}[node distance=4cm]
      \node[node, anchor=west] (owner) at (0,-5) {Data Controller};
      \draw[->] ([xshift=0em]owner.north) -- ([xshift=0em]2,-0.5);
    \end{scope}

    \node[txt] (list_req) [below=of owner, xshift=0em, yshift=1.5em] {$listen("request\_processing")$};

    \begin{scope}
      \node[node, anchor=west] (processor) at (0,5) {Data Processor};
      \draw[<-] ([xshift=0em]processor.south) -- ([xshift=0em]2,0.5) node[midway,right] {$Tx(\{requestID, Enc_{pk_P}(k)\}, "notify\_processor")$};
    \end{scope}

    \node[txt] (list_req_cr) [above=of processor, xshift=0em, yshift=-1.5em] {$listen("processing")$};

    \begin{scope}
      \node[node, anchor=east] (requester) at (\textwidth,-5) {Requester};
      \draw[->] ([xshift=0em]requester.north) -- ([xshift=0em]14.45,-0.5) node[midway,left] {\small $Tx(\{dataSetID, queryID, pubKey\}, "request\_processing")$};
    \end{scope}

  \end{tikzpicture}
  \caption{Request for processing}
  \label{fig:arch:req_pr}
\end{figure}

\subsection{Dataset processing}
\label{solution:flow:pr_data}

As it has already been mentioned in our study, the role of a data processor is crucial. By task assignments, it decrease the pressure over data controllers which they exploit them by entrusting specific data processing operations on behalf of data requestors. Data processors can only perform pre-agreed algorithms (ยง~\ref{solution:algorithms}) on datasets. Each processing must be accompanied by a proof of correctness of computation and an encrypted output which are published on the blockchain. A processor is constantly listening for \verb|process| events related to it. The controller notify the processor by emitting those events including the ID of the request and the encrypted symmetric key of the dataset. The processor, having all the needed information, signs a transaction to get the details of that request; the dataset ID and the algorithm ID. Another transaction is made to get the location and the hash of the dataset. As all informations are saved only in the blockchain, for traceability, accountability and provenance tracking to be enabled, those transactions are needed. The processor is ready to process the dataset. At first, it decrypts the symmetric key with its private key $sk_p$, downloads the dataset from the provided location and decrypts it. Assuming no errors, the computation is started and a proof, as analyzed in~\ref{solution:proof}, is generated with the evaluation key $ek_f$. The results are encrypted with the public key of the processor $pk_r$. Final, a transaction is sent to the blockchain with the proof $\pi$ and the encrypted results and an event is emitted to notify the requestor for the completion of the procedure.

The data processing procedure is summarized in Algorithm~\ref{alg:data_processing}.

\begin{algorithm}[!htb]
  \caption{Dataset processing}\label{alg:data_processing}
  \begin{algorithmic}[1]
  \Procedure{\sf process}{e}
    \Let{(\textsf{requestID}, \textsf{algorithmID}, c_{k}, pk_r)}{e}
    \Let{tx}{(\textsf{requestID})} \Comment{Get dataset id}
    \Let{(\textsf{datasetID}, \textsf{\textsf{algorithmID}})}{(tx)} \Comment{Get dataset info}
    \Let{(\textsf{location}, h)}{(tx)}
    \Let{k}{Dec_{sk_{p}}(c_{k})} \Comment{Decrypt symmetric key}
    \Let{c_{d}}{\textsf{get(location)}} \Comment{Get encrypted dataset}
    \Let{d}{Dec_{k}(c_{d})} \Comment{Decrypt dataset}
    \CommentLine{Process dataset and get proof of computation}
    \State $s \rselect{\{0, 1\}^{l}}$ \Comment{Salt generation with security parameter}
    \Let{F}{\textsf{algorithms['algorithmID']}}
    \Let{u}{(h, s)} \Comment{Public input}
    \Let{w}{d} \Comment{Private input}
    \Let{(\pi, \textsf{out})}{zkp(ek_f, F, u, w)} \Comment{Algorithm~\ref{alg:zkp}}
    \Let{tx}{(\pi, Enc_{pk_r}(\textsf{out}))} \Comment{Send results to requestor}
    \State $tx$.send()
  \EndProcedure
  \Procedure{\sf watch}{\null}
    \While{$e \in$ events['process']} \Comment{Listen data processing notifications}
      \State process($e$) \Comment{Process request}
    \EndWhile
  \EndProcedure
  \end{algorithmic}
\end{algorithm}

\subsection{Proof verification}
\label{solution:flow:verify}

The requestor, as zkSNARKs are non-interactive, can verify any time the correctness of the processing. It can either watch for \verb|process_done| events or by manually checking into the blockchain if a proof exists. Either way, is in its best interest to verify the proof. A transaction has again to be sent for request information retrieval. By sending the request ID the requestor gets the proof and the encrypted results. Then, it decrypts the results and verifies the proof with the verification key $vk_f$. In case of verification failure or the value of the \verb|valid| output variable is \verb|false| the proof is rejected.

The verification procedure is summarized in Algorithm~\ref{alg:data_verify}.

\begin{algorithm}[!htb]
  \caption{Proof verification}\label{alg:data_verify}
  \begin{algorithmic}[1]
  \Procedure{\sf verify}{e}
    \Let{(requestID)}{e}
    \Let{tx}{(requestID)}
    \Let{(proof)}{(tx)} \Comment{Get request info}
    \Let{(h, c)}{proof}
    \Let{(\pi, \textsf{out})}{Dec_{sk_{r}}(c)} \Comment{Decrypt results}
    \Let{\textsf{($y$, valid, $s$)}}{\textsf{out}}
    \Let{result}{\_verify(\pi, y, valid, s, vk_f)} \Comment{Verify proof}
    \If{!valid || !result} \Comment{Reject if not valid}
      \State \textbf{reject}
    \EndIf
  \EndProcedure
  \Procedure{\sf watch}{\null}
    \While{$e \in$ events['process\_done']} \Comment{Listen data processing completion}
      \State verify($e$) \Comment{Process request}
    \EndWhile
  \EndProcedure
  \end{algorithmic}
\end{algorithm}

\begin{figure}[ht!]
  \begin{tikzpicture}

    \node[blockchain] (blockchain) at (0,0){Blockchain};

    \begin{scope}
      \node[node, anchor=west] (processor) at (0,5) {Data Processor};
      \draw[->] ([xshift=0em]processor.south) -- ([xshift=0em]2,0.5) node[midway,right] {$Tx(\{requestID, Enc_{pk_R}(\pi, y)\}, "notify\_requester")$};
    \end{scope}

    \node[node, process] (compute) [above of=processor, yshift=3cm] {$Compute$};

    \draw[->] ([xshift=-1em]compute.south) -- ([xshift=-1em]2,5.5) node[midway,left] {$(y, \pi)$};
    \draw[<-] ([xshift=1em]compute.south) -- ([xshift=1em]2,5.5)  node[midway,right] {$dataset$};

    \begin{scope}
      \node[node, anchor=east] (requester) at (\textwidth,-5) {Requester};
      \draw[<-] (requester.north) -- (14.45,-0.5) node[midway,right] {$Verify_{vk}(\pi, y)$};
    \end{scope}

  \end{tikzpicture}
  \caption{Data processing}
  \label{fig:arch:process}
\end{figure}

\begin{figure}[ht!]
  \begin{tikzpicture}

    \node[blockchain] (blockchain) at (0,0){Blockchain};

    \begin{scope}[node distance=4cm]
      \node[node, anchor=west] (owner) at (0,-5) {Data Controller};
      \node[database] (db) [below right=of owner] {Database};
      \draw[<->] (owner) -- (db) node[midway,left] {$Enc_k(data)$};
      \draw[<-] ([xshift=-1em]owner.north) -- ([xshift=-1em]2,-0.5);
      \draw[->] ([xshift=1em]owner.north) -- ([xshift=1em]2,-0.5) node[midway,right] {$Enc_{pk_P}(k, metadata)$};
    \end{scope}

    \begin{scope}
      \node[node, anchor=west] (processor) at (0,5) {Data Processor};
      \draw[<-] ([xshift=-1em]processor.south) -- ([xshift=-1em]2,0.5);
      \draw[->] ([xshift=1em]processor.south) -- ([xshift=1em]2,0.5) node[midway,right] {$Enc_{pk_R}(result, \pi)$};
    \end{scope}

    \begin{scope}
      \node[node, anchor=east] (requester) at (\textwidth,-5) {Requester};
      \draw[->] ([xshift=-1em]requester.north) -- ([xshift=-1em]14.45,-0.5) node[midway,left] {$Request(pk_R, pred)$};
      \draw[<-] ([xshift=1em]requester.north) -- ([xshift=1em]14.45,-0.5) node[midway,right]  {$Verify_{vk}(\pi)$};
    \end{scope}

  \end{tikzpicture}
  \caption{Architecture}
  \label{fig:architecture}
\end{figure}
